---
title: "Analysis of Exponential Distribution and Central Limit Theorem"
author: "Kevin E. D'Elia"
date: "February 15, 2016"
output: pdf_document
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.path='figures/')
```

# Overview (Synopsis of Analysis)
The Central Limit Theorem (CLT), and the concept of the sampling distribution, are critical for understanding why statistical inference works.  The CLT says that if you take many repeated samples from a population, then calculate the averages (or sum) of each one, the collection of those averages will be normally distributed.  The purpose of this project is to examine the mean and variance of a sample from the exponential distribution, then produce a sampling distribution of the mean and variance, and finally demonstrate how the sampling distribution is approximately normal.

# Simulations

As with any good simulation, the first step is to set the seed for the random number generators.  This is done so that the results generated by the random number engine will be consistent across all invocations of the code, thus ensuring that the results are reproducible by other interested parties.

```{r}
set.seed(1234)
```

The R code for the simulations will be included in-line with the report for easy verification, along with explanations about what is being accomplished by each R markdown code chunk.

There will be two simulations run.  The first will draw 40 values from the exponential distribution.  The second will perform the first simulation, except that it will be executed 10,000 times and, for each execution, the mean and variance will calculated for the sample and stored in a vector. The idea behind this last point is you keep taking a sample of size **n** from the population, calculate some statistic on it, such as the mean, store that value and repeat the process, using a large number of repetitions and increasing sample sizes.  This results in what is known as a **sampling distribution**.  Note that this report will not alter the sample size.

The exponential distribution can be simulated in R with **rexp(n, lambda)** where $\lambda$ is the *rate* parameter.  The mean of exponential distribution is $\frac{1}{\lambda}$ and the standard deviation is also $\frac{1}{\lambda}$.  A requirement of this report is to set $\lambda$ = 0.2 for all of the simulations.  I chose 10,000 replications because this number is large enough to ensure that the mean of the sampling distribution approaches the mean of the population.

# Sample Mean versus Theoretical Mean:

The first step in the analysis is to draw 40 random expontenials, like so:
```{r sample1}
lambda <- 0.2
n <- 40
sample1 <- rexp(n, lambda)
```

For comparison, and as a step in demonstrating the approach, a second sample is drawn, using a new seed to ensure distinct randomness (otherwise, the previous seed will be used and the distribution will be identical):
```{r sample2}
set.seed(9898)
sample2 <- rexp(n, lambda)
```

The sample mean is computed for each sample and this is what the values look like:
```{r table_of_means, echo=FALSE}
sample1_mean = mean(sample1)
sample2_mean = mean(sample2)
Sample <- c("Sample 1", "Sample 2")
Mean <- c(round(sample1_mean, 2), round(sample2_mean, 2))
theTable <- data.frame(Sample, Mean)
rownames(theTable) <- NULL
knitr::kable(theTable)
```

We can quickly see from the table that there is a difference in values between the mean of two samples.  Graphically, this can be shown as:
```{r sample_mean_plots, echo=4:9}
original_par <- par(no.readonly = TRUE)
par(mfrow=c(2,2))
title <- "40 Random Exponentials"
qqnorm(sample1)
hist(sample1, prob = TRUE, col = "yellow", border = "black", xlab = "", main = title)
abline(v = mean(sample1), col = "royalblue", lwd = 2)
qqnorm(sample2)
hist(sample2, prob = TRUE, col = "yellow", border = "black", xlab = "", main = title)
abline(v = mean(sample2), col = "royalblue", lwd = 2)
par(original_par)
```

Several comments are in order regarding the figures:

1. The histograms are not normally distributed 
2. The Q-Q plots indicate that they do not form a normal distribution (** This needs work**)
3. The sample mean in both cases is centered around 5 and we will expect this to approximate the theoretical mean

Now, what happens when this drawing of a sample of size **n** and subsequent calculation of a sample statistic is done repeatedly?  The sample size remains the same, but the calculation is now done 10,000 times.  The following graphic shows the distribution of the sample means, or what is also known as the sampling distribution.

```{r sampling_distribution_of_means}
xbar <- NULL
ul <- 10000
for (i in 1:ul) {xbar <- c(xbar, mean(rexp(n, lambda) ) ) }
hist(xbar, prob = TRUE, xlab = "Means of sample size 40", main = "Sampling Distribution")
abline(v = mean(xbar), col = "royalblue", lwd = 2)
mtext(paste("Theoretical Mean = ", round(mean(xbar), 3)), col = "orange")
```

From this graph, it can be seen that the distribution appears normal in shape.  The balance point, or the "mean of the sample means", appears to be reasonably close to the mean of the distribution from which the samples were drawn.

# Sample Variance versus Theoretical Variance:  

The sample variance is computed for each sample and this is what the values look like:
```{r table_of_variances, echo=FALSE}
sample1_var = var(sample1)
sample2_var = var(sample2)
Sample <- c("Sample 1", "Sample 2")
Variance <- c(round(sample1_var, 2), round(sample2_var, 2))
theTable <- data.frame(Sample, Variance)
rownames(theTable) <- NULL
knitr::kable(theTable)
```

Looking at this data graphically gives the following result:
```{r sample_var_plots, echo=4:9}
original_par <- par(no.readonly = TRUE)
par(mfrow=c(1,2))
title <- "40 Random Exponentials"
hist(sample1, prob = TRUE, col = "yellow", xlim = c(0, 35), xlab = "", main = title)
abline(v = var(sample1), col = "royalblue", lwd = 2)
abline(v = sd(sample1), col = "green", lwd = 3)
hist(sample2, prob = TRUE, col = "yellow", xlim = c(0, 35), xlab = "", main = title)
abline(v = var(sample2), col = "royalblue", lwd = 2)
abline(v = sd(sample2), col = "green", lwd = 3)
par(original_par)
```

It appears that, as the values in the tail increase, so does the variance.

Applying the same reasoning to the sampling distribution of the variance as was done to the mean, the following graphic is the result:
```{r sampling_distribution_of_variances, echo=3:8}
x_label = "Variances of sample size 40"
main_title = "Sampling Distribution"
variances <- NULL
ul <- 10000
for (i in 1:ul) {variances <- c(variances, var(rexp(n, lambda) ) ) }
hist(variances, prob = TRUE, xlab = x_label, main = main_title)
abline(v = var(variances), col = "royalblue", lwd = 2)
mtext(paste("Theoretical Variance = ", round(var(variances), 3)), col = "orange")
```

This distribution appears relatively normal and follows the pattern of the sample wherein, as the upper tail values increase and extend further from the center of the distribution, so does the variances.

# Distribution 

By The Central Limit Theorem, for large n, $\bar{X}$ ~ N($\mu$, $\sigma^2$/n)

The document answers the question "Does the distribution of means of 40 exponentials behave as predicted by the Central Limit theorem?"  From the analysis shown above, it can be stated that this is the case.

In this analysis, the population is all numbers in an exponential distribution.  The sample size taken is 40 and the number of samples taken (which hopefully approximates the population) is 10,000.  The population mean is $\frac{1}{\lambda}$ as is the standard deviation.  In the case of this study, that amounts to 1/0.2 or 5.  It was shown that, for both the sample and the sampling distribution, the mean was very close to 5. In other words, the mean of the sampling distribution is roughly equivalent to the mean of the population.  It was also shown that the standard deviation of the samples approximated the standard deviation of the population.

DO I HAVE TO SHOW THAT THE STANDARD DEVIATION OF THE SAMPLE MEANS (WHICH ARE THE SINGLE SAMPLES) EQUALS THE STANDARD DEVIATION OF THE POPULATION (5) DIVIDED BY THE SQUARE ROOT OF THE SAMPLE (40). SO FAR, I HAVE 5 = 0.8, WHICH IS NOT CORRECT